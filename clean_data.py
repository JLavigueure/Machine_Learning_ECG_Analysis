""""
Clean the processed data and save to pkl file. Removes unwanted features, imputes missing values, and scales the data.
Select features using model-based feature selection and PCA for dimensionality reduction. 
Save the cleaned data to cleaned_data.pkl.

Usage: 
    python clean_data.py 
""" 

import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer # for imputation
from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer # for scaling and binarizing data
from sklearn.ensemble import RandomForestClassifier # for feature selection
from sklearn.feature_selection import SelectFromModel # for feature selection
from sklearn.multioutput import MultiOutputClassifier # for multi-label classification
from sklearn.decomposition import PCA # dimensionality reduction
from sklearn.model_selection import train_test_split # for splitting data
import pickle
import os
import sys

def main():
    # Load the pickled dataframe
    print('Loading raw data...')
    with open('data/processed_data.pkl', 'rb') as f:
        data = pickle.load(f)

    print('Cleaning data...')

    # Remove arbitrary features 
    cols_to_drop = [
        'patient_id', 'nurse', 'site', 'device', 'recording_date', 'report', 'scp_codes', 
        'heart_axis', 'infarction_stadium1', 'infarction_stadium2', 'validated_by', 'second_opinion', 
        'initial_autogenerated_report', 'validated_by_human', 'baseline_drift', 'static_noise', 
        'burst_noise', 'electrodes_problems', 'extra_beats', 'pacemaker', 'filename_lr', 'filename_hr',
        'ecg', 'strat_fold'
    ]
    data.drop(columns=cols_to_drop, axis=1, inplace=True)

    # Remove features with little correlation to target
    cols_to_drop = ['total_voltage_1', 'total_voltage_2', 'total_voltage_3', 'total_voltage_4', 'total_voltage_5',
                    'total_voltage_6', 'total_voltage_7', 'total_voltage_8', 'total_voltage_9', 'total_voltage_10',
                    'total_voltage_11', 'total_voltage_12']
    data.drop(columns=cols_to_drop, axis=1, inplace=True)

    # Drop columns with many missing values or diagnosis data
    columns_to_drop = ['height', 'weight']
    data.drop(columns_to_drop, axis=1, inplace=True)
    data.drop(data[data['diagnostic_superclass'].isna()].index, inplace=True)

    # Split X and y
    y = data['diagnostic_superclass']
    data.drop(columns=['diagnostic_superclass'], axis=1, inplace=True)
    print('Imputing missing values...')
    
    # impute missing values
    imputer = SimpleImputer(strategy='mean')
    data[:] = imputer.fit_transform(data[:])
    
    # Scale data 
    print('Scaling data...')
    scaler = StandardScaler()
    data = pd.DataFrame( 
        scaler.fit_transform(data.astype(np.float64)),
        columns=data.columns,
        index=data.index
    )

    # No categorical data, so no one hot encoding needed

    # Model-based feature selection using Random Forest
    print('Model-based feature selection...')
    mlb = MultiLabelBinarizer()
    y_binarize = mlb.fit_transform(y)
    rf = MultiOutputClassifier(RandomForestClassifier(random_state=61297), n_jobs=-1) 
    rf.fit(data, y_binarize)
    features = set()
    for i, estimator in enumerate(rf.estimators_):
        selected_features = SelectFromModel(estimator, threshold='mean', prefit=True).get_support(indices=True)
        features.update(selected_features)
    data = data.iloc[:, list(features)]
    print(f'Number of features selected: {len(features)}')
    print(f'Features selected: {list(data.columns)}')

    # Apply PCA to reduce dimensionality
    print('Reducing dimensions...')
    pca = PCA(n_components=0.95)  # Keep 95% of variance
    data = pd.DataFrame(pca.fit_transform(data))
    print('Number of components: ', pca.n_components_)
    print('Explained variance: ', str(pca.explained_variance_ratio_.sum()*100) + '%')

    # Split train and test data
    print('Splitting data...')
    X_train, X_test, y_train, y_test = train_test_split(data, y, random_state=61297)

    # Save the cleaned data to a new pickle file
    path = 'data/cleaned_data.pkl' 
    print(path)
    with open(path, 'wb') as f:
        pickle.dump((X_train, X_test, y_train, y_test), f)


if __name__ == "__main__":
    main()